{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Project: Building and Evaluating Reorder Prediction Model\n",
    "\n",
    "This project formulates reorder prediction as a ranking problem and evaluates an XGBoost model against a baseline strategy. The input data is a Kaggle challenge Instacart event-level orders dataset. Performance is assessed using ROC-AUC and per-user Recall@K, highlighting the importance of user-centric evaluation for recommendation systems."
   ],
   "id": "a1d89421d5b5c6b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Imports and Setup**\n",
    "\n",
    "Import data loading utilities and the XGBoost training and validation helpers used throughout the notebook.\n"
   ],
   "id": "7201c92c821eaba6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T14:14:09.012126Z",
     "start_time": "2025-12-16T14:14:05.227900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.data_loader import *\n",
    "from model.xgboost_ import *"
   ],
   "id": "c097aedac8e5d482",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Build Feature and Target Datasets**\n",
    "\n",
    "Generate training and validation datasets with engineered features and the binary reorder target. The data is split according to the specified training partition.\n"
   ],
   "id": "1cb3e538ddbfd40e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T14:14:11.429211Z",
     "start_time": "2025-12-16T14:14:09.018614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, validate_df = build_feature_target_csv(partition_for_training=0.8, Force_rewrite=False)\n",
    "\n",
    "print('Model input features', train_df.columns.tolist()[2:-1])"
   ],
   "id": "6f6f32fee0434c10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input features ['avg_position_in_cart', 'bought_times', 'times_in_last_5_orders', 'time_since_last_order_score', 'user_aisle_freq', 'user_department_freq', 'product_reorder_rate', 'add_to_cart_order', 'avg_time_between_orders', 'user_reorder_rate']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Model Configuration**\n",
    "\n",
    "Define the XGBoost hyperparameters for training a binary logistic model optimized for ranking performance (ROC-AUC).\n"
   ],
   "id": "8979a649809de293"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "PARAMS = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 7,\n",
    "    'min_child_weight': 5,\n",
    "    'gamma': 0.1,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_estimators': 400,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'reg_alpha': 0.05,\n",
    "    'reg_lambda': 1.0,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "}"
   ],
   "id": "66173bed126c856c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Model Training and Prediction**\n",
    "\n",
    "Train an XGBoost model using the selected feature set to predict reorder likelihood for each user–product pair. Feed the validation dataset\n"
   ],
   "id": "1f41968a08101dfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T14:14:54.931585Z",
     "start_time": "2025-12-16T14:14:11.469261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = xgb_train(train_df=train_df,\n",
    "                  feature_columns=train_df.columns[2:12],\n",
    "                  target_column='reordered',\n",
    "                  params = PARAMS)\n",
    "\n",
    "df_model = xgb_validate(model=model,\n",
    "                                validate_df=validate_df,\n",
    "                                feature_columns=validate_df.columns[2:12],\n",
    "                                target_column='reordered')\n",
    "\n",
    "print(df_model)\n",
    "\n",
    "df_model.to_csv(data_dir/'raw'/'model_output.csv', index=True)\n"
   ],
   "id": "9fb9c6fe5382166e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  y_true     score\n",
      "0              5       0  0.104450\n",
      "1              5       0  0.120275\n",
      "2              5       0  0.068323\n",
      "3              5       0  0.276848\n",
      "4              5       0  0.497227\n",
      "...          ...     ...       ...\n",
      "1637606   206195       0  0.082295\n",
      "1637607   206195       0  0.030781\n",
      "1637608   206195       0  0.052682\n",
      "1637609   206195       1  0.138630\n",
      "1637610   206195       0  0.035720\n",
      "\n",
      "[1637611 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Baseline: Top-20 Previously Ordered Products**\n",
    "\n",
    "The baseline recommends the 20 most frequently ordered products for each user using historical order counts. These products are marked as predicted reorders and used as a heuristic benchmark for comparison against the machine-learning model.\n"
   ],
   "id": "2e5f3360e4f8ac2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_baseline = build_baseline(orders_prior, order_products_prior, order_products_train, True)",
   "id": "de9fd02e9a7a4566"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Mean Recall@K (Per User) Evaluation**\n",
    "\n",
    "Compute Mean Recall@K by ranking predictions per user, measuring how many of the user’s actual reorders appear in their top-K recommendations, and averaging recall across users.\n"
   ],
   "id": "96772c8fd2aa5e88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T14:14:54.946035Z",
     "start_time": "2025-12-16T14:14:54.943964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recall_at_k_per_user(df, k):\n",
    "    recalls = []\n",
    "\n",
    "    for _, g in df.groupby('user_id'):\n",
    "        y_true = g['y_true'].to_numpy()\n",
    "        scores = g['score'].to_numpy()\n",
    "\n",
    "        positives = y_true.sum()\n",
    "        if positives == 0:\n",
    "            continue  # or treat as recall = 0, depending on convention\n",
    "\n",
    "        idx = np.argsort(scores)[::-1][:k]\n",
    "        y_topk = y_true[idx]\n",
    "\n",
    "        recall_u = y_topk.sum() / positives\n",
    "        recalls.append(recall_u)\n",
    "\n",
    "    return np.mean(recalls) if recalls else 0.0"
   ],
   "id": "e54c7436b2e2c8c7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Evaluation Output, involving ROC AUC score comparison**",
   "id": "63b874197a484c05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T14:14:59.031867Z",
     "start_time": "2025-12-16T14:14:54.950729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "r_model = recall_at_k_per_user(\n",
    "    df_model,\n",
    "    k=20\n",
    ")\n",
    "\n",
    "r_base = recall_at_k_per_user(\n",
    "    df_baseline.rename(columns={'reordered': 'y_true', 'pred_reordered': 'score'}),\n",
    "    k=20\n",
    ")\n",
    "\n",
    "model_roc_auc = roc_auc_score(df_model['y_true'], df_model['score'])\n",
    "baseline_roc_auc = roc_auc_score(df_baseline['reordered'], df_baseline['pred_reordered'])\n",
    "\n",
    "print(f'MODEL      ROC AUC Score: {model_roc_auc:.4f}')\n",
    "print(f'BASELINE   ROC AUC Score: {baseline_roc_auc:.4f}')\n",
    "print(f'MODEL      Mean R@50:     {r_model:.4f}')\n",
    "print(f'BASELINE   Mean R@50:     {r_base:.4f}')"
   ],
   "id": "76b6505b69c9b825",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL      ROC AUC Score: 0.8261\n",
      "BASELINE   ROC AUC Score: 0.5768\n",
      "MODEL      Mean R@50:     0.7585\n",
      "BASELINE   Mean R@50:     0.4576\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Compared to the baseline heuristic, the XGBoost model substantially improves both global ranking quality\n",
    "and user-level recommendation effectiveness.\n",
    "The model achieves a ROC-AUC of ~0.83 versus ~0.58 for the baseline, representing a\n",
    "**53% relative improvement** in ranking performance.\n",
    "More importantly, at the decision level, the model retrieves\n",
    "~76% of items users actually reorder within the top-20 recommendations, compared to\n",
    "~46% for the baseline, a\n",
    "**66% relative improvement**.\n",
    " This demonstrates that the model not only ranks items more accurately overall, but also surfaces\n",
    " significantly more relevant items in the top-K positions where decisions are made."
   ],
   "id": "3114d0ec3c79dcb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
